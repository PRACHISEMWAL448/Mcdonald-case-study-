{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45511b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#reading file\n",
    "df = pd.read_csv(\"mcdonalds.csv\")\n",
    "df.head()\n",
    "\n",
    "yummy\tconvenient\tspicy\tfattening\tgreasy\tfast\tcheap\ttasty\texpensive\thealthy\tdisgusting\tLike\tAge\tVisitFrequency\tGender\n",
    "0\tNo\tYes\tNo\tYes\tNo\tYes\tYes\tNo\tYes\tNo\tNo\t-3\t61\tEvery three months\tFemale\n",
    "1\tYes\tYes\tNo\tYes\tYes\tYes\tYes\tYes\tYes\tNo\tNo\t+2\t51\tEvery three months\tFemale\n",
    "2\tNo\tYes\tYes\tYes\tYes\tYes\tNo\tYes\tYes\tYes\tNo\t+1\t62\tEvery three months\tFemale\n",
    "3\tYes\tYes\tNo\tYes\tYes\tYes\tYes\tYes\tNo\tNo\tYes\t+4\t69\tOnce a week\tFemale\n",
    "4\tNo\tYes\tNo\tYes\tYes\tYes\tYes\tNo\tNo\tYes\tNo\t+2\t49\tOnce a month\tMale\n",
    "df.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1453 entries, 0 to 1452\n",
    "Data columns (total 15 columns):\n",
    " #   Column          Non-Null Count  Dtype \n",
    "---  ------          --------------  ----- \n",
    " 0   yummy           1453 non-null   object\n",
    " 1   convenient      1453 non-null   object\n",
    " 2   spicy           1453 non-null   object\n",
    " 3   fattening       1453 non-null   object\n",
    " 4   greasy          1453 non-null   object\n",
    " 5   fast            1453 non-null   object\n",
    " 6   cheap           1453 non-null   object\n",
    " 7   tasty           1453 non-null   object\n",
    " 8   expensive       1453 non-null   object\n",
    " 9   healthy         1453 non-null   object\n",
    " 10  disgusting      1453 non-null   object\n",
    " 11  Like            1453 non-null   object\n",
    " 12  Age             1453 non-null   int64 \n",
    " 13  VisitFrequency  1453 non-null   object\n",
    " 14  Gender          1453 non-null   object\n",
    "dtypes: int64(1), object(14)\n",
    "memory usage: 170.4+ KB\n",
    "df.shape\n",
    "(1453, 15)\n",
    "df.describe()\n",
    "Age\n",
    "count\t1453.000000\n",
    "mean\t44.604955\n",
    "std\t14.221178\n",
    "min\t18.000000\n",
    "25%\t33.000000\n",
    "50%\t45.000000\n",
    "75%\t57.000000\n",
    "max\t71.000000\n",
    "df.isna().sum()\n",
    "yummy             0\n",
    "convenient        0\n",
    "spicy             0\n",
    "fattening         0\n",
    "greasy            0\n",
    "fast              0\n",
    "cheap             0\n",
    "tasty             0\n",
    "expensive         0\n",
    "healthy           0\n",
    "disgusting        0\n",
    "Like              0\n",
    "Age               0\n",
    "VisitFrequency    0\n",
    "Gender            0\n",
    "dtype: int64\n",
    "#variable counts\n",
    "df['Gender'].value_counts()\n",
    "Female    788\n",
    "Male      665\n",
    "Name: Gender, dtype: int64\n",
    "df['VisitFrequency'].value_counts()\n",
    "Once a month             439\n",
    "Every three months       342\n",
    "Once a year              252\n",
    "Once a week              235\n",
    "Never                    131\n",
    "More than once a week     54\n",
    "Name: VisitFrequency, dtype: int64\n",
    "df['Like'].value_counts()\n",
    "+3              229\n",
    "+2              187\n",
    "0               169\n",
    "+4              160\n",
    "+1              152\n",
    "I hate it!-5    152\n",
    "I love it!+5    143\n",
    "-3               73\n",
    "-4               71\n",
    "-2               59\n",
    "-1               58\n",
    "Name: Like, dtype: int64\n",
    "Step 1: Deciding (not) to Segment\n",
    "Step 2: Specifying the Ideal Target Segment\n",
    "Step 3: Collecting Data\n",
    "Step 4: Exploring Data\n",
    "# Target Segmentation \n",
    "#1 Segmenting based on age and gender (Sociodemographic Segmentation)\n",
    "labels = ['Female', 'Male']\n",
    "size = df['Gender'].value_counts()\n",
    "colors = ['orange', 'blue']\n",
    "explode = [0, 0.1]\n",
    "plt.rcParams['figure.figsize'] = (7, 7)\n",
    "plt.pie(size, colors = colors, explode = explode, labels = labels, shadow = True, autopct = '%.2f%%')\n",
    "plt.title('Gender', fontsize = 20)\n",
    "plt.axis('off')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Percentage proporation of female is customers in more than male customers\n",
    "\n",
    "# Age based Segmentation\n",
    "plt.figure(figsize=(15,6))\n",
    "a = sns.countplot(x = df['Age'])\n",
    "plt.title('Age based segmentation', fontsize=15)\n",
    "# Maximum customers of mcdonalds belongs to age group 30-40 and 50-60\n",
    "Text(0.5, 1.0, 'Age based segmentation')\n",
    "\n",
    "# Psychographic Segmentation\n",
    "# Replacing text in Like column with numbered values for convience\n",
    "df['Like'] = df['Like'].replace({'I hate it!-5': '-5','I love it!+5':'+5'})\n",
    "\n",
    "sns.barplot(x='Like', y='Age', data=df)\n",
    "plt.title('Ratings of Mcdonald')\n",
    "Text(0.5, 1.0, 'Ratings of Mcdonald')\n",
    "\n",
    "# Label encoding for categorical varibales\n",
    "# First 11 columns are categorical in nature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df_cat = df.iloc[:,0:11]\n",
    "df_cat\n",
    "yummy\tconvenient\tspicy\tfattening\tgreasy\tfast\tcheap\ttasty\texpensive\thealthy\tdisgusting\n",
    "0\tNo\tYes\tNo\tYes\tNo\tYes\tYes\tNo\tYes\tNo\tNo\n",
    "1\tYes\tYes\tNo\tYes\tYes\tYes\tYes\tYes\tYes\tNo\tNo\n",
    "2\tNo\tYes\tYes\tYes\tYes\tYes\tNo\tYes\tYes\tYes\tNo\n",
    "3\tYes\tYes\tNo\tYes\tYes\tYes\tYes\tYes\tNo\tNo\tYes\n",
    "4\tNo\tYes\tNo\tYes\tYes\tYes\tYes\tNo\tNo\tYes\tNo\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "1448\tNo\tYes\tNo\tYes\tYes\tNo\tNo\tNo\tYes\tNo\tYes\n",
    "1449\tYes\tYes\tNo\tYes\tNo\tNo\tYes\tYes\tNo\tYes\tNo\n",
    "1450\tYes\tYes\tNo\tYes\tNo\tYes\tNo\tYes\tYes\tNo\tNo\n",
    "1451\tYes\tYes\tNo\tNo\tNo\tYes\tYes\tYes\tNo\tYes\tNo\n",
    "1452\tNo\tYes\tNo\tYes\tYes\tNo\tNo\tNo\tYes\tNo\tYes\n",
    "1453 rows × 11 columns\n",
    "\n",
    "def labelling(x):\n",
    "    df[x] = LabelEncoder().fit_transform(df[x])\n",
    "    return df\n",
    "\n",
    "df_cat = df.iloc[:,0:11]\n",
    "for i in df_cat:\n",
    "    labelling(i)\n",
    "    \n",
    "df\n",
    "yummy\tconvenient\tspicy\tfattening\tgreasy\tfast\tcheap\ttasty\texpensive\thealthy\tdisgusting\tLike\tAge\tVisitFrequency\tGender\n",
    "0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t0\t0\t-3\t61\tEvery three months\tFemale\n",
    "1\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t+2\t51\tEvery three months\tFemale\n",
    "2\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t+1\t62\tEvery three months\tFemale\n",
    "3\t1\t1\t0\t1\t1\t1\t1\t1\t0\t0\t1\t+4\t69\tOnce a week\tFemale\n",
    "4\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\t+2\t49\tOnce a month\tMale\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "1448\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t-5\t47\tOnce a year\tMale\n",
    "1449\t1\t1\t0\t1\t0\t0\t1\t1\t0\t1\t0\t+2\t36\tOnce a week\tFemale\n",
    "1450\t1\t1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t+3\t52\tOnce a month\tFemale\n",
    "1451\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t0\t+4\t41\tEvery three months\tMale\n",
    "1452\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t-3\t30\tEvery three months\tMale\n",
    "1453 rows × 15 columns\n",
    "\n",
    "# Histogram of the each attributes\n",
    "plt.rcParams['figure.figsize'] = (12,14)\n",
    "df.hist()\n",
    "plt.show()\n",
    "\n",
    "# Converting 11 categorical columns into array\n",
    "x = df_cat.values\n",
    "x\n",
    "array([[0, 1, 0, ..., 1, 0, 0],\n",
    "       [1, 1, 0, ..., 1, 0, 0],\n",
    "       [0, 1, 1, ..., 1, 1, 0],\n",
    "       ...,\n",
    "       [1, 1, 0, ..., 1, 0, 0],\n",
    "       [1, 1, 0, ..., 0, 1, 0],\n",
    "       [0, 1, 0, ..., 1, 0, 1]])\n",
    "# Calculating mean of 11 columns\n",
    "round(df.iloc[:,0:11].mean(),2)\n",
    "yummy         0.55\n",
    "convenient    0.91\n",
    "spicy         0.09\n",
    "fattening     0.87\n",
    "greasy        0.53\n",
    "fast          0.90\n",
    "cheap         0.60\n",
    "tasty         0.64\n",
    "expensive     0.36\n",
    "healthy       0.20\n",
    "disgusting    0.24\n",
    "dtype: float64\n",
    "PRINCIPAL COMPONENT ANALYSIS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "pca_data = preprocessing.scale(x)\n",
    "\n",
    "pca = PCA(n_components=11)\n",
    "pc = pca.fit_transform(x)\n",
    "names = ['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11']\n",
    "pf= pd.DataFrame(data = pc, columns = names)\n",
    "pf\n",
    "pc1\tpc2\tpc3\tpc4\tpc5\tpc6\tpc7\tpc8\tpc9\tpc10\tpc11\n",
    "0\t0.425367\t-0.219079\t0.663255\t-0.401300\t0.201705\t-0.389767\t-0.211982\t0.163235\t0.181007\t0.515706\t-0.567074\n",
    "1\t-0.218638\t0.388190\t-0.730827\t-0.094724\t0.044669\t-0.086596\t-0.095877\t-0.034756\t0.111476\t0.493313\t-0.500440\n",
    "2\t0.375415\t0.730435\t-0.122040\t0.692262\t0.839643\t-0.687406\t0.583112\t0.364379\t-0.322288\t0.061759\t0.242741\n",
    "3\t-0.172926\t-0.352752\t-0.843795\t0.206998\t-0.681415\t-0.036133\t-0.054284\t-0.231477\t-0.028003\t-0.250678\t-0.051034\n",
    "4\t0.187057\t-0.807610\t0.028537\t0.548332\t0.854074\t-0.097305\t-0.457043\t0.171758\t-0.074409\t0.031897\t0.082245\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "1448\t1.550242\t0.275031\t-0.013737\t0.200604\t-0.145063\t0.306575\t-0.075308\t0.345552\t-0.136589\t-0.432798\t-0.456076\n",
    "1449\t-0.957339\t0.014308\t0.303843\t0.444350\t-0.133690\t0.381804\t-0.326432\t0.878047\t-0.304441\t-0.247443\t-0.193671\n",
    "1450\t-0.185894\t1.062662\t0.220857\t-0.467643\t-0.187757\t-0.192703\t-0.091597\t-0.036576\t0.038255\t0.056518\t-0.012800\n",
    "1451\t-1.182064\t-0.038570\t0.561561\t0.701126\t0.047645\t0.193687\t-0.027335\t-0.339374\t0.022267\t-0.002573\t-0.105316\n",
    "1452\t1.550242\t0.275031\t-0.013737\t0.200604\t-0.145063\t0.306575\t-0.075308\t0.345552\t-0.136589\t-0.432798\t-0.456076\n",
    "1453 rows × 11 columns\n",
    "\n",
    "pf.head()\n",
    "pc1\tpc2\tpc3\tpc4\tpc5\tpc6\tpc7\tpc8\tpc9\tpc10\tpc11\n",
    "0\t0.425367\t-0.219079\t0.663255\t-0.401300\t0.201705\t-0.389767\t-0.211982\t0.163235\t0.181007\t0.515706\t-0.567074\n",
    "1\t-0.218638\t0.388190\t-0.730827\t-0.094724\t0.044669\t-0.086596\t-0.095877\t-0.034756\t0.111476\t0.493313\t-0.500440\n",
    "2\t0.375415\t0.730435\t-0.122040\t0.692262\t0.839643\t-0.687406\t0.583112\t0.364379\t-0.322288\t0.061759\t0.242741\n",
    "3\t-0.172926\t-0.352752\t-0.843795\t0.206998\t-0.681415\t-0.036133\t-0.054284\t-0.231477\t-0.028003\t-0.250678\t-0.051034\n",
    "4\t0.187057\t-0.807610\t0.028537\t0.548332\t0.854074\t-0.097305\t-0.457043\t0.171758\t-0.074409\t0.031897\t0.082245\n",
    "pf.describe()\n",
    "pc1\tpc2\tpc3\tpc4\tpc5\tpc6\tpc7\tpc8\tpc9\tpc10\tpc11\n",
    "count\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\t1.453000e+03\n",
    "mean\t2.307552e-17\t-4.137548e-17\t-2.110918e-17\t4.322840e-17\t4.515773e-17\t-3.961808e-17\t4.406890e-17\t-5.539654e-17\t-2.976131e-17\t5.616063e-17\t1.134674e-17\n",
    "std\t7.570495e-01\t6.074556e-01\t5.046195e-01\t3.987986e-01\t3.374050e-01\t3.102746e-01\t2.896973e-01\t2.751220e-01\t2.652511e-01\t2.488418e-01\t2.369028e-01\n",
    "min\t-1.188421e+00\t-1.040274e+00\t-8.808133e-01\t-5.906209e-01\t-1.045938e+00\t-8.524911e-01\t-8.059463e-01\t-9.316201e-01\t-9.557606e-01\t-8.871971e-01\t-8.851439e-01\n",
    "25%\t-5.476794e-01\t-3.568482e-01\t-4.507793e-01\t-2.814986e-01\t-2.433247e-01\t-1.927027e-01\t-1.342190e-01\t-1.717258e-01\t-1.181233e-01\t-1.465751e-01\t-1.053163e-01\n",
    "50%\t-7.074592e-02\t-1.151632e-01\t2.687734e-02\t-1.163200e-01\t3.348785e-02\t-3.460184e-02\t-6.366220e-02\t-3.475619e-02\t3.868061e-02\t3.020635e-02\t-1.201409e-02\n",
    "75%\t4.933012e-01\t3.915540e-01\t3.515939e-01\t2.702298e-01\t2.048293e-01\t1.747453e-01\t2.318357e-02\t1.295966e-01\t7.987794e-02\t7.001416e-02\t8.554080e-02\n",
    "max\t1.705573e+00\t1.279130e+00\t1.326976e+00\t1.355278e+00\t1.053327e+00\t1.323793e+00\t1.350886e+00\t1.121388e+00\t1.086693e+00\t1.181524e+00\t9.255829e-01\n",
    "# Proportion of Variance (from PC1 to PC11)\n",
    "pca.explained_variance_ratio_\n",
    "array([0.29944723, 0.19279721, 0.13304535, 0.08309578, 0.05948052,\n",
    "       0.05029956, 0.0438491 , 0.03954779, 0.0367609 , 0.03235329,\n",
    "       0.02932326])\n",
    "np.cumsum(pca.explained_variance_ratio_)\n",
    "array([0.29944723, 0.49224445, 0.6252898 , 0.70838558, 0.7678661 ,\n",
    "       0.81816566, 0.86201476, 0.90156255, 0.93832345, 0.97067674,\n",
    "       1.        ])\n",
    "# Correlation coefficient between original variables and the component\n",
    "\n",
    "loadings = pca.components_\n",
    "num_pc = pca.n_features_\n",
    "pc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\n",
    "loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))\n",
    "loadings_df['variable'] = df_cat.columns.values\n",
    "loadings_df = loadings_df.set_index('variable')\n",
    "loadings_df\n",
    "PC1\tPC2\tPC3\tPC4\tPC5\tPC6\tPC7\tPC8\tPC9\tPC10\tPC11\n",
    "variable\t\t\t\t\t\t\t\t\t\t\t\n",
    "yummy\t-0.476933\t0.363790\t-0.304444\t0.055162\t-0.307535\t0.170738\t-0.280519\t0.013041\t0.572403\t-0.110284\t0.045439\n",
    "convenient\t-0.155332\t0.016414\t-0.062515\t-0.142425\t0.277608\t-0.347830\t-0.059738\t-0.113079\t-0.018465\t-0.665818\t-0.541616\n",
    "spicy\t-0.006356\t0.018809\t-0.037019\t0.197619\t0.070620\t-0.355087\t0.707637\t0.375934\t0.400280\t-0.075634\t0.141730\n",
    "fattening\t0.116232\t-0.034094\t-0.322359\t-0.354139\t-0.073405\t-0.406515\t-0.385943\t0.589622\t-0.160512\t-0.005338\t0.250910\n",
    "greasy\t0.304443\t-0.063839\t-0.802373\t0.253960\t0.361399\t0.209347\t0.036170\t-0.138241\t-0.002847\t0.008707\t0.001642\n",
    "fast\t-0.108493\t-0.086972\t-0.064642\t-0.097363\t0.107930\t-0.594632\t-0.086846\t-0.627799\t0.166197\t0.239532\t0.339265\n",
    "cheap\t-0.337186\t-0.610633\t-0.149310\t0.118958\t-0.128973\t-0.103241\t-0.040449\t0.140060\t0.076069\t0.428087\t-0.489283\n",
    "tasty\t-0.471514\t0.307318\t-0.287265\t-0.002547\t-0.210899\t-0.076914\t0.360453\t-0.072792\t-0.639086\t0.079184\t0.019552\n",
    "expensive\t0.329042\t0.601286\t0.024397\t0.067816\t-0.003125\t-0.261342\t-0.068385\t0.029539\t0.066996\t0.454399\t-0.490069\n",
    "healthy\t-0.213711\t0.076593\t0.192051\t0.763488\t0.287846\t-0.178226\t-0.349616\t0.176303\t-0.185572\t-0.038117\t0.157608\n",
    "disgusting\t0.374753\t-0.139656\t-0.088571\t0.369539\t-0.729209\t-0.210878\t-0.026792\t-0.167181\t-0.072483\t-0.289592\t-0.040662\n",
    "# Correlation matrix plot for loadings \n",
    "plt.rcParams['figure.figsize'] = (20,15)\n",
    "ax = sns.heatmap(loadings_df, annot=True, cmap='inferno')\n",
    "plt.show()\n",
    "\n",
    "# Scree plot (Elbow test) - PCA\n",
    "from bioinfokit.visuz import cluster\n",
    "cluster.screeplot(obj=[pc_list, pca.explained_variance_ratio_],show=True,dim=(10,5))\n",
    "\n",
    "plt.scatter(pf.pc1, pf.pc2)\n",
    "plt.title('PC1 against PC2')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "Text(0, 0.5, 'PC2')\n",
    "\n",
    "# Get PC scores\n",
    "pca_scores = PCA().fit_transform(x)\n",
    "\n",
    "# Get 2D biplot\n",
    "cluster.biplot(cscore=pca_scores, loadings=loadings, labels=df.columns.values, var1=round(pca.explained_variance_ratio_[0]*100, 2),\n",
    "    var2=round(pca.explained_variance_ratio_[1]*100, 2),show=True,dim=(10,5))\n",
    "\n",
    "Step 5: Extracting Segments\n",
    "# Using k-means clustering analysis\n",
    "from sklearn.utils.metaestimators import available_if\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(1,12)).fit(df_cat)\n",
    "visualizer.show()\n",
    "\n",
    "<AxesSubplot:title={'center':'Distortion Score Elbow for KMeans Clustering'}, xlabel='k', ylabel='distortion score'>\n",
    "# K-means Clustering \n",
    "\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(df_cat)\n",
    "df['cluster_num'] = kmeans.labels_ # Adding to df\n",
    "print (kmeans.labels_) # Label assigned for each data point\n",
    "print (kmeans.inertia_) # Gives within-cluster sum of squares. \n",
    "print(kmeans.n_iter_) # Number of iterations that k-means algorithm runs to get a minimum within-cluster sum of squares\n",
    "print(kmeans.cluster_centers_) # Location of the centroids on each cluster.\n",
    "[2 0 0 ... 0 1 3]\n",
    "1603.0604440558945\n",
    "7\n",
    "[[0.85448916 0.9628483  0.13312693 0.90712074 0.61919505 0.86068111\n",
    "  0.10835913 0.93188854 0.89783282 0.20433437 0.10526316]\n",
    " [0.88793103 0.98103448 0.0862069  0.79482759 0.32931034 0.96034483\n",
    "  0.92241379 0.97586207 0.01724138 0.32068966 0.04310345]\n",
    " [0.02302632 0.89144737 0.07236842 0.92434211 0.66776316 0.96381579\n",
    "  0.93421053 0.15460526 0.01315789 0.07236842 0.38815789]\n",
    " [0.0203252  0.68292683 0.08536585 0.91463415 0.69512195 0.73170732\n",
    "  0.06504065 0.08943089 0.87804878 0.06097561 0.71544715]]\n",
    "# To see each cluster size\n",
    "from collections import Counter\n",
    "Counter(kmeans.labels_)\n",
    "Counter({2: 304, 0: 323, 1: 580, 3: 246})\n",
    "# Visulazing clusters\n",
    "sns.scatterplot(data=pf, x=\"pc1\", y=\"pc2\", hue=kmeans.labels_)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n",
    "            marker=\"X\", c=\"r\", s=80, label=\"centroids\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Hierarchical Clustering Algorithm\n",
    "# Create demogram and find the best clustering value\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "merg = linkage(df_cat, method='ward')\n",
    "plt.rcParams['figure.figsize'] = (25,10)\n",
    "dendrogram(merg,leaf_rotation = 90)\n",
    "plt.xlabel(\"data points\", fontsize = 15)\n",
    "plt.ylabel(\"euclidean distance\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "Step 7: Describing Segments\n",
    "# Describing Segments\n",
    "\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from itertools import product\n",
    "\n",
    "crosstab =pd.crosstab(df['cluster_num'],df['Like'])\n",
    "# Reordering cols\n",
    "crosstab = crosstab[['-5','-4','-3','-2','-1','0','+1','+2','+3','+4','+5']]\n",
    "crosstab \n",
    "Like\t-5\t-4\t-3\t-2\t-1\t0\t+1\t+2\t+3\t+4\t+5\n",
    "cluster_num\t\t\t\t\t\t\t\t\t\t\t\n",
    "0\t5\t3\t7\t6\t7\t36\t42\t60\t66\t47\t44\n",
    "1\t4\t4\t2\t6\t13\t43\t65\t90\t143\t111\t99\n",
    "2\t54\t36\t34\t28\t25\t51\t31\t31\t12\t2\t0\n",
    "3\t89\t28\t30\t19\t13\t39\t14\t6\t8\t0\t0\n",
    "plt.rcParams['figure.figsize'] = (7,5)\n",
    "mosaic(crosstab.stack())\n",
    "plt.show()\n",
    "\n",
    "# Mosaic plot gender vs segment\n",
    "crosstab_gender =pd.crosstab(df['cluster_num'],df['Gender'])\n",
    "crosstab_gender\n",
    "Gender\tFemale\tMale\n",
    "cluster_num\t\t\n",
    "0\t154\t169\n",
    "1\t349\t231\n",
    "2\t179\t125\n",
    "3\t106\t140\n",
    "plt.rcParams['figure.figsize'] = (7,5)\n",
    "mosaic(crosstab_gender.stack())\n",
    "plt.show()\n",
    "\n",
    "# Box plot for age\n",
    "\n",
    "sns.boxplot(x=\"cluster_num\", y=\"Age\", data=df)\n",
    "<AxesSubplot:xlabel='cluster_num', ylabel='Age'>\n",
    "\n",
    "Step 8: Selecting the targets segments\n",
    "# Calculating the mean\n",
    "# Visit frequency\n",
    "df['VisitFrequency'] = LabelEncoder().fit_transform(df['VisitFrequency'])\n",
    "visit = df.groupby('cluster_num')['VisitFrequency'].mean()\n",
    "visit = visit.to_frame().reset_index()\n",
    "visit\n",
    "cluster_num\tVisitFrequency\n",
    "0\t0\t2.547988\n",
    "1\t1\t2.584483\n",
    "2\t2\t2.822368\n",
    "3\t3\t2.654472\n",
    "# Like\n",
    "df['Like'] = LabelEncoder().fit_transform(df['Like'])\n",
    "Like = df.groupby('cluster_num')['Like'].mean()\n",
    "Like = Like.to_frame().reset_index()\n",
    "Like\n",
    "cluster_num\tLike\n",
    "0\t0\t3.275542\n",
    "1\t1\t2.962069\n",
    "2\t2\t6.171053\n",
    "3\t3\t7.422764\n",
    "# Gender\n",
    "df['Gender'] = LabelEncoder().fit_transform(df['Gender'])\n",
    "Gender = df.groupby('cluster_num')['Gender'].mean()\n",
    "Gender = Gender.to_frame().reset_index()\n",
    "Gender\n",
    "cluster_num\tGender\n",
    "0\t0\t0.523220\n",
    "1\t1\t0.398276\n",
    "2\t2\t0.411184\n",
    "3\t3\t0.569106\n",
    "segment = Gender.merge(Like, on='cluster_num', how='left').merge(visit, on='cluster_num', how='left')\n",
    "segment\n",
    "cluster_num\tGender\tLike\tVisitFrequency\n",
    "0\t0\t0.523220\t3.275542\t2.547988\n",
    "1\t1\t0.398276\t2.962069\t2.584483\n",
    "2\t2\t0.411184\t6.171053\t2.822368\n",
    "3\t3\t0.569106\t7.422764\t2.654472\n",
    "# Target segments\n",
    "\n",
    "plt.figure(figsize = (9,4))\n",
    "sns.scatterplot(x = \"VisitFrequency\", y = \"Like\",data=segment,s=400, color=\"r\")\n",
    "plt.title(\"Simple segment evaluation plot for the fast food data set\",\n",
    "          fontsize = 15) \n",
    "plt.xlabel(\"Visit\", fontsize = 12) \n",
    "plt.ylabel(\"Like\", fontsize = 12) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d8661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6149eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
